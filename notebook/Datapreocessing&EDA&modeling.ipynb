{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc143252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working in: C:\\Users\\YASH\\AI,ML book\\CodSoft\\Task-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\YASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\YASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\YASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import joblib\n",
    "import kaggle\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set up directory\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Change to project folder\n",
    "os.chdir(r\"C:\\Users\\YASH\\AI,ML book\\CodSoft\\Task-1\")\n",
    "print(\"Now working in:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29e7ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    kaggle.api.dataset_download_files(\\n        \\'hijest/genre-classification-dataset-imdb\\',\\n        path=\\'data/raw/\\',\\n        unzip=True\\n    )\\n    print(\"Dataset downloaded successfully!\")\\nexcept:\\n    print(\"Dataset already exists or error in downloading\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset using Kaggle API\n",
    "'''\n",
    "try:\n",
    "    kaggle.api.dataset_download_files(\n",
    "        'hijest/genre-classification-dataset-imdb',\n",
    "        path='data/raw/',\n",
    "        unzip=True\n",
    "    )\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "except:\n",
    "    print(\"Dataset already exists or error in downloading\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86103775",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836dfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from text file\n",
    "# Load the training data\n",
    "train_file = 'data/raw/Genre Classification Dataset/train_data.txt'\n",
    "test_file = 'data/raw/Genre Classification Dataset/test_data.txt'\n",
    "test_solution_file = 'data/raw/Genre Classification Dataset/test_data_solution.txt'\n",
    "\n",
    "# Data loading function\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load data from text file\"\"\"\n",
    "    ids = []\n",
    "    titles = []\n",
    "    genres = []\n",
    "    descriptions = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':::' in line:\n",
    "                parts = line.strip().split(' ::: ')\n",
    "                if len(parts) == 4:\n",
    "                    ids.append(parts[0])\n",
    "                    titles.append(parts[1])\n",
    "                    genres.append(parts[2])\n",
    "                    descriptions.append(parts[3])\n",
    "                elif len(parts) == 3:\n",
    "                    ids.append(parts[0])\n",
    "                    titles.append(parts[1])\n",
    "                    genres.append('')\n",
    "                    descriptions.append(parts[2])\n",
    "                else:\n",
    "                    ids.append(parts[0])\n",
    "                    titles.append(parts[1])\n",
    "                    genres.append(parts[2])\n",
    "                    descriptions.append(' ::: '.join(parts[3:]))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'ID': ids,\n",
    "        'Title': titles,\n",
    "        'Genre': genres,\n",
    "        'Description': descriptions\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2db890",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (54214, 4)\n",
      "Test data shape: (54200, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data(train_file)\n",
    "test_df = load_data(test_file)\n",
    "test_solution_df = load_data(test_solution_file)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c250a91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                       Title        Genre  \\\n",
      "0          1                Oscar et la dame rose (2009)        drama   \n",
      "1          2                                Cupid (1997)     thriller   \n",
      "2          3            Young, Wild and Wonderful (1980)        adult   \n",
      "3          4                       The Secret Sin (1915)        drama   \n",
      "4          5                      The Unrecovered (2007)        drama   \n",
      "...      ...                                         ...          ...   \n",
      "54209  54210                             \"Bonino\" (1953)       comedy   \n",
      "54210  54211                 Dead Girls Don't Cry (????)       horror   \n",
      "54211  54212   Ronald Goedemondt: Ze bestaan echt (2008)  documentary   \n",
      "54212  54213                    Make Your Own Bed (1944)       comedy   \n",
      "54213  54214  Nature's Fury: Storm of the Century (2006)      history   \n",
      "\n",
      "                                             Description  \n",
      "0      Listening in to a conversation between his doc...  \n",
      "1      A brother and sister with a past incestuous re...  \n",
      "2      As the bus empties the students for their fiel...  \n",
      "3      To help their unemployed father make ends meet...  \n",
      "4      The film's title refers not only to the un-rec...  \n",
      "...                                                  ...  \n",
      "54209  This short-lived NBC live sitcom centered on B...  \n",
      "54210  The NEXT Generation of EXPLOITATION. The siste...  \n",
      "54211  Ze bestaan echt, is a stand-up comedy about gr...  \n",
      "54212  Walter and Vivian live in the country and have...  \n",
      "54213  On Labor Day Weekend, 1935, the most intense h...  \n",
      "\n",
      "[54214 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c30ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                           Title Genre  \\\n",
      "0          1            Edgar's Lunch (1998)         \n",
      "1          2        La guerra de pap√° (1977)         \n",
      "2          3     Off the Beaten Track (2010)         \n",
      "3          4          Meu Amigo Hindu (2015)         \n",
      "4          5               Er nu zhai (1955)         \n",
      "...      ...                             ...   ...   \n",
      "54195  54196  \"Tales of Light & Dark\" (2013)         \n",
      "54196  54197     Der letzte Mohikaner (1965)         \n",
      "54197  54198             Oliver Twink (2007)         \n",
      "54198  54199               Slipstream (1973)         \n",
      "54199  54200       Curitiba Zero Grau (2010)         \n",
      "\n",
      "                                             Description  \n",
      "0      L.R. Brane loves his life - his car, his apart...  \n",
      "1      Spain, March 1964: Quico is a very naughty chi...  \n",
      "2      One year in the life of Albin and his family o...  \n",
      "3      His father has died, he hasn't spoken with his...  \n",
      "4      Before he was known internationally as a marti...  \n",
      "...                                                  ...  \n",
      "54195  Covering multiple genres, Tales of Light & Dar...  \n",
      "54196  As Alice and Cora Munro attempt to find their ...  \n",
      "54197  A movie 169 years in the making. Oliver Twist,...  \n",
      "54198  Popular, but mysterious rock D.J Mike Mallard ...  \n",
      "54199  Curitiba is a city in movement, with rhythms a...  \n",
      "\n",
      "[54200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying enhanced text preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\YASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def enhanced_text_processing(text):\n",
    "    \"\"\"Enhanced text processing with lemmatization and better tokenization\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters but keep basic punctuation and numbers\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\!\\?]', '', text)\n",
    "        \n",
    "        # Tokenization\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "        \n",
    "        # Lemmatization (better than stemming)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Applying enhanced text preprocessing...\")\n",
    "train_df['clean_combined'] = train_df['Description'].apply(enhanced_text_processing)\n",
    "test_df['clean_combined'] = test_df['Description'].apply(enhanced_text_processing)\n",
    "\n",
    "# Combine title and description for analysis\n",
    "train_df['combined_text'] = train_df['Title'] + ' ' + train_df['Description']\n",
    "test_df['combined_text'] = test_df['Title'] + ' ' + test_df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87497eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBasic Info:\")\n",
    "print(train_df.info())\n",
    "print(f\"\\n{'='*10}test data info{'='*10}\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b262c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(f\"\\n{'='*10}test data missing values{'='*10}\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDuplicate Values:\")\n",
    "print(train_df.duplicated().sum())\n",
    "print(f\"\\n{'='*10}test data duplicate values{'='*10}\")\n",
    "print(test_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genra distribution analysis\n",
    "\n",
    "print(\"\\nGenre Distribution:\")\n",
    "genre_counts = train_df['Genre'].value_counts()\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a6207",
   "metadata": {},
   "source": [
    "## 4. EDA (Exploratory data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize genre distribution\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')\n",
    "plt.title('Distribution of Movie Genres', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Genre', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/genre_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Text Length Analysis\n",
    "# Text length analysis\n",
    "train_df['text_length'] = train_df['clean_combined'].str.len()\n",
    "train_df['word_count'] = train_df['clean_combined'].str.split().str.len()\n",
    "\n",
    "print(f\"\\nAverage Text Length: {train_df['text_length'].mean():.0f} characters\")\n",
    "print(f\"Average Word Count: {train_df['word_count'].mean():.0f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae56fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance by keeping only major genres\n",
    "major_genres = genre_counts[genre_counts > 1000].index\n",
    "train_df_filtered = train_df[train_df['Genre'].isin(major_genres)]\n",
    "\n",
    "print(f\"\\nGenres after filtering: {len(major_genres)}\")\n",
    "print(f\"Training data shape after filtering: {train_df_filtered.shape}\")\n",
    "\n",
    "# Align test data with test solution for major genres\n",
    "test_solution_filtered = test_solution_df[test_solution_df['Genre'].isin(major_genres)]\n",
    "test_ids_with_solutions = test_solution_filtered['ID']\n",
    "test_df_filtered = test_df[test_df['ID'].isin(test_ids_with_solutions)]\n",
    "\n",
    "print(f\"Test data shape after filtering: {test_df_filtered.shape}\")\n",
    "print(f\"Test solution shape after filtering: {test_solution_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea12980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Description length by genre\n",
    "# Text length by genre\n",
    "plt.figure(figsize=(12, 6))\n",
    "train_df.boxplot(column='word_count', by='Genre', figsize=(12, 6))\n",
    "plt.title('Word Count Distribution by Genre')\n",
    "plt.suptitle('')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/word_count_by_genre.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65001a",
   "metadata": {},
   "source": [
    "## 5. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "X = train_df_filtered['clean_combined']\n",
    "y = train_df_filtered['Genre']\n",
    "\n",
    "X_test = test_df_filtered['clean_combined']\n",
    "y_test = test_solution_filtered['Genre']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06661304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Model Training with Hyperparameter Tuning\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Define models with hyperparameter grids\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(\n",
    "            random_state=42, \n",
    "            class_weight=class_weight_dict,\n",
    "            max_iter=1000\n",
    "        ),\n",
    "        'params': {\n",
    "            'tfidf__max_features': [5000, 10000],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "            'model__C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'model': LinearSVC(\n",
    "            random_state=42, \n",
    "            class_weight=class_weight_dict,\n",
    "            max_iter=10000\n",
    "        ),\n",
    "        'params': {\n",
    "            'tfidf__max_features': [5000, 10000],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "            'model__C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'MultinomialNB': {\n",
    "        'model': MultinomialNB(),\n",
    "        'params': {\n",
    "            'tfidf__max_features': [5000, 10000],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "            'model__alpha': [0.1, 0.5, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ed056",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "results = {}\n",
    "\n",
    "print(\"\\nTraining models with hyperparameter tuning...\")\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', lowercase=True)),\n",
    "        ('model', model_info['model'])\n",
    "    ])\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        model_info['params'], \n",
    "        cv=3, \n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    \n",
    "    # Validate\n",
    "    val_pred = best_pipeline.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': best_pipeline,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Update best model\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_model = best_pipeline\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Final Model Evaluation\n",
    "\n",
    "print(\"\\nEvaluating best model on test set...\")\n",
    "\n",
    "# Verify test data alignment\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "\n",
    "if X_test.shape[0] == y_test.shape[0]:\n",
    "    # Test the best model\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, test_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=best_model.classes_, \n",
    "                yticklabels=best_model.classes_)\n",
    "    plt.title('Confusion Matrix - Test Set', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: Test data misaligned! Features: {X_test.shape[0]}, Target: {y_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30103c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Model Persistence\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f'models/best_genre_classifier_{best_model_name}.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\nBest model saved as: {model_filename}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer separately for potential reuse\n",
    "vectorizer_filename = 'models/tfidf_vectorizer.pkl'\n",
    "if hasattr(best_model, 'named_steps'):\n",
    "    vectorizer = best_model.named_steps['tfidf']\n",
    "    joblib.dump(vectorizer, vectorizer_filename)\n",
    "    print(f\"TF-IDF vectorizer saved as: {vectorizer_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Model Comparison and Results\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Validation Accuracy: {result['val_accuracy']:.4f}\")\n",
    "    print(f\"  Best Parameters: {result['best_params']}\")\n",
    "\n",
    "print(f\"\\nFINAL RESULTS:\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Validation Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Prediction Function for New Data\n",
    "\n",
    "def predict_genre(text, model=best_model):\n",
    "    \"\"\"Predict genre for new text\"\"\"\n",
    "    if model is not None:\n",
    "        if hasattr(model, 'predict'):\n",
    "            prediction = model.predict([text])[0]\n",
    "            \n",
    "            # Get probabilities if available\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                probabilities = model.predict_proba([text])[0]\n",
    "                confidence = max(probabilities)\n",
    "                all_probs = dict(zip(model.classes_, probabilities))\n",
    "            else:\n",
    "                confidence = 1.0\n",
    "                all_probs = {}\n",
    "            \n",
    "            result = {\n",
    "                'predicted_genre': prediction,\n",
    "                'confidence': confidence,\n",
    "                'all_probabilities': all_probs\n",
    "            }\n",
    "            return result\n",
    "    return {\"error\": \"Model not available for predictions\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30649cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "sample_text = \"A group of friends go on an adventure to find hidden treasure in the mountains.\"\n",
    "prediction = predict_genre(sample_text)\n",
    "print(f\"\\nExample Prediction:\")\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted Genre: {prediction['predicted_genre']}\")\n",
    "print(f\"Confidence: {prediction['confidence']:.4f}\")\n",
    "\n",
    "print(\"\\nModel training and evaluation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
